{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jwjeong/anaconda3/envs/quant/lib/python3.8/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "/home/jwjeong/anaconda3/envs/quant/lib/python3.8/site-packages/torch/_utils.py:831: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  return self.fget.__get__(instance, owner)()\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForCausalLM\n",
    "\n",
    "#model_id = \"meta-llama/Llama-2-7b-hf\"\n",
    "model_id = \"facebook/opt-1.3b\"\n",
    "model = AutoModelForCausalLM.from_pretrained(model_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers.pytorch_utils import Conv1D\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "def get_weight_minmax_gpt2(model):\n",
    "    weight_min = {}\n",
    "    weight_max = {}\n",
    "    for name, module in model.named_moWdules():\n",
    "        if (isinstance(module, Conv1D)) | isinstance(module, nn.Linear):\n",
    "            if name.split('.')[-1] in ['c_fc', 'c_proj', 'c_attn']:\n",
    "                if name.split('.')[-2] in ['attn', 'mlp']:\n",
    "                    comp_name = '.'.join(name.split('.')[-2:])\n",
    "                    if  comp_name in weight_min:\n",
    "                        weight_min[comp_name].append(torch.min(module.weight).item())\n",
    "                        weight_max[comp_name].append(torch.max(module.weight).item())\n",
    "                    else:\n",
    "                        weight_min[comp_name] = []\n",
    "                        weight_max[comp_name] = []\n",
    "                        weight_min[comp_name].append(torch.min(module.weight).item())\n",
    "                        weight_max[comp_name].append(torch.max(module.weight).item())\n",
    "    \n",
    "    return weight_min, weight_max\n",
    "\n",
    "def get_weight_minmax_opt(model):\n",
    "    weight_min = {}\n",
    "    weight_max = {}\n",
    "    for name, module in model.named_modules():\n",
    "        if (isinstance(module, Conv1D)) | isinstance(module, nn.Linear):\n",
    "            if name.split('.')[-1] in ['q_proj', 'k_proj', 'v_proj', 'out_proj', 'fc1', 'fc2']:\n",
    "                comp_name = '.'.join(name.split('.')[-1:])\n",
    "                if  comp_name in weight_min:\n",
    "                    weight_min[comp_name].append(torch.min(module.weight).item())\n",
    "                    weight_max[comp_name].append(torch.max(module.weight).item())\n",
    "                else:\n",
    "                    weight_min[comp_name] = []\n",
    "                    weight_max[comp_name] = []\n",
    "                    weight_min[comp_name].append(torch.min(module.weight).item())\n",
    "                    weight_max[comp_name].append(torch.max(module.weight).item())\n",
    "    \n",
    "    return weight_min, weight_max\n",
    "\n",
    "def get_weight_minmax_llama(model):\n",
    "    weight_min = {}\n",
    "    weight_max = {}\n",
    "    for name, module in model.named_modules():\n",
    "        if (isinstance(module, Conv1D)) | isinstance(module, nn.Linear):\n",
    "            if name.split('.')[-1] in ['q_proj', 'k_proj', 'v_proj', 'o_proj', 'up_proj', 'down_proj', 'gate_proj']:\n",
    "                comp_name = '.'.join(name.split('.')[-1:])\n",
    "                if  comp_name in weight_min:\n",
    "                    weight_min[comp_name].append(torch.min(module.weight).item())\n",
    "                    weight_max[comp_name].append(torch.max(module.weight).item())\n",
    "                else:\n",
    "                    weight_min[comp_name] = []\n",
    "                    weight_max[comp_name] = []\n",
    "                    weight_min[comp_name].append(torch.min(module.weight).item())\n",
    "                    weight_max[comp_name].append(torch.max(module.weight).item())\n",
    "    \n",
    "    return weight_min, weight_max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from quant import quant, dequant\n",
    "bits = 16\n",
    "gs = 128\n",
    "scale, zero, qs = quant(bits, gs, model)\n",
    "q_x = dequant(scale, zero, qs, gs, bits)\n",
    "for key in q_x.keys():\n",
    "    if key.split('.')[-1] != 'lm_head':\n",
    "        weight = key+'.weight'\n",
    "        model.state_dict()[weight][:] = q_x[key]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "min, max = get_weight_minmax_opt(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k_proj [-0.24174661934375763, -0.27865371108055115, -0.27822643518447876, -0.2794552445411682, -0.28324615955352783, -0.29386502504348755, -0.3181660771369934, -0.29851433634757996, -0.2978433072566986, -0.29903721809387207, -0.28878435492515564, -0.29673653841018677, -0.2962765395641327, -0.299712598323822, -0.2977583408355713, -0.28110450506210327, -0.28653380274772644, -0.28155767917633057, -0.2879585921764374, -0.2852679491043091, -0.2938303053379059, -0.2783399820327759, -0.2747690975666046, -0.27728962898254395]\n",
      "v_proj [-0.13668617606163025, -0.18865646421909332, -0.14202116429805756, -0.1341332644224167, -0.11230236291885376, -0.11180998384952545, -0.10690794885158539, -0.16197851300239563, -0.14110782742500305, -0.11453115940093994, -0.12665385007858276, -0.13032442331314087, -0.1416580229997635, -0.11882098764181137, -0.1360282003879547, -0.1497844010591507, -0.12516529858112335, -0.14367319643497467, -0.1507648229598999, -0.16286520659923553, -0.1891021579504013, -0.17004181444644928, -0.17778047919273376, -0.23989908397197723]\n",
      "q_proj [-0.27164310216903687, -0.2702829837799072, -0.2822265326976776, -0.2659212350845337, -0.2761000394821167, -0.2780455946922302, -0.2742503583431244, -0.2742525339126587, -0.29228314757347107, -0.27393877506256104, -0.26391252875328064, -0.2498360425233841, -0.2751000225543976, -0.24886654317378998, -0.23995135724544525, -0.2702437937259674, -0.2180425375699997, -0.2701370120048523, -0.27045729756355286, -0.15390178561210632, -0.17499612271785736, -0.18046027421951294, -0.16812020540237427, -0.27730271220207214]\n",
      "out_proj [-0.5558063983917236, -0.5663899183273315, -0.5391454696655273, -0.31331196427345276, -0.28326356410980225, -0.28751635551452637, -0.2771981358528137, -0.2890501618385315, -0.28319495916366577, -0.2905839681625366, -0.2783399820327759, -0.2817297577857971, -0.2730324864387512, -0.2665933668613434, -0.2766842544078827, -0.2728825509548187, -0.2880741059780121, -0.33924704790115356, -0.28471678495407104, -0.27503687143325806, -0.30759507417678833, -0.39802244305610657, -0.5016972422599792, -0.4729658365249634]\n",
      "fc1 [-0.2746625244617462, -0.2636641263961792, -0.28152063488960266, -0.2539864480495453, -0.25749415159225464, -0.261886328458786, -0.24648740887641907, -0.22575508058071136, -0.231463223695755, -0.2638091742992401, -0.28333327174186707, -0.28319495916366577, -0.26963701844215393, -0.2038070261478424, -0.2144608050584793, -0.19442562758922577, -0.23773784935474396, -0.2397879809141159, -0.22847001254558563, -0.27128085494041443, -0.20596392452716827, -0.253278523683548, -0.24645254015922546, -0.27656319737434387]\n",
      "fc2 [-0.5485050678253174, -0.5564790368080139, -0.5342826843261719, -0.3241879343986511, -0.2841786742210388, -0.2816143035888672, -0.29210883378982544, -0.28732848167419434, -0.28411149978637695, -0.27294492721557617, -0.27132436633110046, -0.2797951102256775, -0.2756006121635437, -0.2765927314758301, -0.2703719735145569, -0.27303245663642883, -0.27368396520614624, -0.2779650092124939, -0.2846579849720001, -0.29952529072761536, -0.28368186950683594, -0.46174776554107666, -0.2936515212059021, -0.38847655057907104]\n"
     ]
    }
   ],
   "source": [
    "for key in min.keys():\n",
    "    print(key, min[key])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k_proj [0.2100357562303543, 0.2476140260696411, 0.2359100580215454, 0.2441413849592209, 0.24294601380825043, 0.2544305622577667, 0.27317431569099426, 0.2588602602481842, 0.25662460923194885, 0.26618748903274536, 0.255293071269989, 0.2631424069404602, 0.26078569889068604, 0.26001396775245667, 0.26080653071403503, 0.24541430175304413, 0.25928768515586853, 0.2481663078069687, 0.24270963668823242, 0.2424391359090805, 0.2517335116863251, 0.24165232479572296, 0.24728302657604218, 0.2423408329486847]\n",
      "v_proj [0.0793766975402832, 0.1335023194551468, 0.1391310840845108, 0.1291218250989914, 0.13099807500839233, 0.09936639666557312, 0.08989805728197098, 0.1453159600496292, 0.12123468518257141, 0.10891036689281464, 0.09447711706161499, 0.10221104323863983, 0.13590817153453827, 0.1189442127943039, 0.12522746622562408, 0.13419455289840698, 0.11442945152521133, 0.12514424324035645, 0.12424957752227783, 0.13308241963386536, 0.16024285554885864, 0.14878658950328827, 0.1554727703332901, 0.14566776156425476]\n",
      "q_proj [0.24322783946990967, 0.2462218850851059, 0.2488861083984375, 0.23000892996788025, 0.24616137146949768, 0.24148020148277283, 0.2416277378797531, 0.24439860880374908, 0.2410849630832672, 0.24502091109752655, 0.23899680376052856, 0.17426565289497375, 0.22510451078414917, 0.2369787096977234, 0.20324566960334778, 0.23766714334487915, 0.1867261826992035, 0.23734940588474274, 0.2372170388698578, 0.18590909242630005, 0.14814171195030212, 0.1646081954240799, 0.18180100619792938, 0.2416447401046753]\n",
      "out_proj [0.4447655975818634, 0.499480277299881, 0.43898507952690125, 0.27414795756340027, 0.25771409273147583, 0.25157681107521057, 0.26789039373397827, 0.25291889905929565, 0.2516692876815796, 0.25426095724105835, 0.2553008496761322, 0.26365357637405396, 0.2509429454803467, 0.2492482215166092, 0.2528797686100006, 0.25251665711402893, 0.25206485390663147, 0.29684117436408997, 0.27491146326065063, 0.25433245301246643, 0.2691456973552704, 0.35100263357162476, 0.43898507952690125, 0.41384512186050415]\n",
      "fc1 [0.24361182749271393, 0.24126650393009186, 0.24633055925369263, 0.2252274602651596, 0.2252652794122696, 0.2299237996339798, 0.18207333981990814, 0.2014715075492859, 0.2277241051197052, 0.24779558181762695, 0.24852190911769867, 0.2497401386499405, 0.23778383433818817, 0.21584613621234894, 0.19311530888080597, 0.21654216945171356, 0.20440125465393066, 0.23275519907474518, 0.23640936613082886, 0.2337878793478012, 0.21012656390666962, 0.23824968934059143, 0.21321329474449158, 0.27985092997550964]\n",
      "fc2 [0.48639115691185, 0.4801535904407501, 0.48086848855018616, 0.4790414273738861, 0.40349534153938293, 0.45378372073173523, 0.31143346428871155, 0.4526413679122925, 0.433666855096817, 0.47986239194869995, 0.4806831181049347, 0.4809744656085968, 0.47479715943336487, 0.4716990292072296, 0.47627246379852295, 0.3300977945327759, 0.29993006587028503, 0.45402586460113525, 0.25972649455070496, 0.2507990896701813, 0.29237961769104004, 0.4602145254611969, 0.4649808704853058, 0.3091978132724762]\n"
     ]
    }
   ],
   "source": [
    "for key in max.keys():\n",
    "    print(key, max[key])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "custom",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
